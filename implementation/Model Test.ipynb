{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Spark directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"First App\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sql = sqlContext.read.format('com.databricks.spark.csv').options(header='false', inferschema='true').load('tweets_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|      _c0|                 _c1|\n",
      "+---------+--------------------+\n",
      "|emergency|unable to sit due...|\n",
      "|emergency|pnr no need mdica...|\n",
      "|emergency|mobile stolen , n...|\n",
      "|emergency|no water supply i...|\n",
      "|emergency|fan isnt working ...|\n",
      "|emergency|paid for ac but f...|\n",
      "|emergency|big mouse found b...|\n",
      "|emergency|hanging chains of...|\n",
      "|emergency|aggressive copass...|\n",
      "|emergency|having ticket con...|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_sql.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      _c0|count|\n",
      "+---------+-----+\n",
      "| feedback|  275|\n",
      "|emergency|  246|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "data_sql.groupBy(\"_c0\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset and Spliting into train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"tweets_cleaned.csv\")\n",
    "train_data, test_data = data.randomSplit([0.9, 0.1])\n",
    "train_fields = train_data.map(lambda x: x.split(\",\"))\n",
    "train_documents = train_fields.map(lambda x: x[1].lower().split(\" \"))\n",
    "test_fields = test_data.map(lambda x: x.split(\",\"))\n",
    "test_documents = test_fields.map(lambda x: x[1].lower().split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('emergency,unable to sit due to sticky stains on berth. PNR no . do help immediately',\n",
       " SparseVector(16384, {2996: 3.8754, 3408: 5.4848, 6351: 2.1706, 6797: 3.1256, 7294: 4.3862, 7338: 3.4699, 9334: 3.5389, 10620: 2.3278, 10907: 4.7916, 11835: 5.4848, 13751: 2.8106, 14437: 5.4848, 14535: 4.7916, 15094: 5.4848}))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.feature import IDF\n",
    "\n",
    "hashingTF = HashingTF(2**14)\n",
    "tf = hashingTF.transform(train_documents)\n",
    "tf.cache()\n",
    "idf = IDF().fit(tf)\n",
    "tfidf = idf.transform(tf)\n",
    "train_xformedData=train_data.zip(tfidf)\n",
    "train_xformedData.cache()\n",
    "train_xformedData.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('tfidf.model', 'wb') as f:\n",
    "#     pickle.dump(idf, f)\n",
    "\n",
    "# import joblib\n",
    "# joblib.dump(idf, 'tfidf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('emergency,\"mobile stolen , need emergency help to track it pnr\"',\n",
       " SparseVector(16384, {0: 2.8457, 7833: 6.1779, 12550: 5.4848}))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF = HashingTF(2**14)\n",
    "tf_test = hashingTF.transform(test_documents)\n",
    "tf_test.cache()\n",
    "# idf = IDF().fit(tf_test)\n",
    "tfidf = idf.transform(tf_test)\n",
    "\n",
    "test_xformedData=test_data.zip(tfidf)\n",
    "test_xformedData.cache()\n",
    "test_xformedData.collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Labeled Points of training and testing data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "def convertToLabeledPoint(inVal) :\n",
    "    origAttr=inVal[0].split(\",\")\n",
    "    sentiment = 0.0 if origAttr[0] == \"feedback\" else 1.0\n",
    "    return LabeledPoint(sentiment, inVal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, (16384,[2996,3408,6351,6797,7294,7338,9334,10620,10907,11835,13751,14437,14535,15094],[3.8753590210565547,5.484796933490655,2.1706109288181294,3.1256471944186814,4.386184644822546,3.46989391294839,3.5388867844353418,2.3277965123405417,4.791649752930709,5.484796933490655,2.810648284064126,5.484796933490655,4.791649752930709,5.484796933490655]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_points=train_xformedData.map(convertToLabeledPoint)\n",
    "train_labeled_points.cache()\n",
    "train_labeled_points.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, (16384,[0,7833,12550],[2.8457396038753964,6.1779441140506,5.484796933490655]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labeled_points=test_xformedData.map(convertToLabeledPoint)\n",
    "test_labeled_points.cache()\n",
    "test_labeled_points.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training points:  481\n"
     ]
    }
   ],
   "source": [
    "print('Training points: ',len(train_labeled_points.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Points:  40\n"
     ]
    }
   ],
   "source": [
    "print('Testing Points: ',len(test_labeled_points.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "model = NaiveBayes.train(train_labeled_points, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.8544698544698545\n"
     ]
    }
   ],
   "source": [
    "train_predictionAndLabel = train_labeled_points.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * train_predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / train_labeled_points.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.75\n"
     ]
    }
   ],
   "source": [
    "test_predictionAndLabel = test_labeled_points.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * test_predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / test_labeled_points.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NB.model']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'NB.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  186|\n",
      "|  0.0|       1.0|   31|\n",
      "|  1.0|       0.0|   39|\n",
      "|  0.0|       0.0|  225|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = sqlContext.createDataFrame(\n",
    "    [[float(tup[0]), float(tup[1])] for tup in train_predictionAndLabel.collect()],\n",
    "    [\"prediction\",\"label\"]\n",
    ")\n",
    "predDF.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   15|\n",
      "|  0.0|       1.0|    4|\n",
      "|  1.0|       0.0|    6|\n",
      "|  0.0|       0.0|   15|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = sqlContext.createDataFrame(\n",
    "    [[float(tup[0]), float(tup[1])] for tup in test_predictionAndLabel.collect()],\n",
    "    [\"prediction\",\"label\"]\n",
    ")\n",
    "predDF.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "model = SVMWithSGD.train(train_labeled_points, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.8711018711018711\n"
     ]
    }
   ],
   "source": [
    "train_predictionAndLabel = train_labeled_points.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * train_predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / train_labeled_points.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.625\n"
     ]
    }
   ],
   "source": [
    "test_predictionAndLabel = test_labeled_points.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * test_predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / test_labeled_points.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  185|\n",
      "|  0.0|       1.0|   22|\n",
      "|  1.0|       0.0|   40|\n",
      "|  0.0|       0.0|  234|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = sqlContext.createDataFrame(\n",
    "    [[float(tup[0]), float(tup[1])] for tup in train_predictionAndLabel.collect()],\n",
    "    [\"prediction\",\"label\"]\n",
    ")\n",
    "predDF.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   11|\n",
      "|  0.0|       1.0|    5|\n",
      "|  1.0|       0.0|   10|\n",
      "|  0.0|       0.0|   14|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = sqlContext.createDataFrame(\n",
    "    [[float(tup[0]), float(tup[1])] for tup in test_predictionAndLabel.collect()],\n",
    "    [\"prediction\",\"label\"]\n",
    ")\n",
    "predDF.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "model = LogisticRegressionWithLBFGS.train(train_labeled_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.8794178794178794\n"
     ]
    }
   ],
   "source": [
    "train_predictionAndLabel = train_labeled_points.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * train_predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / train_labeled_points.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.675\n"
     ]
    }
   ],
   "source": [
    "test_predictionAndLabel = test_labeled_points.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * test_predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / test_labeled_points.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  189|\n",
      "|  0.0|       1.0|   22|\n",
      "|  1.0|       0.0|   36|\n",
      "|  0.0|       0.0|  234|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = sqlContext.createDataFrame(\n",
    "    [[float(tup[0]), float(tup[1])] for tup in train_predictionAndLabel.collect()],\n",
    "    [\"prediction\",\"label\"]\n",
    ")\n",
    "predDF.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   12|\n",
      "|  0.0|       1.0|    4|\n",
      "|  1.0|       0.0|    9|\n",
      "|  0.0|       0.0|   15|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = sqlContext.createDataFrame(\n",
    "    [[float(tup[0]), float(tup[1])] for tup in test_predictionAndLabel.collect()],\n",
    "    [\"prediction\",\"label\"]\n",
    ")\n",
    "predDF.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
